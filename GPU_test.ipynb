{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeICv8MQXpJum83sNx9+Hu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hfathie/qso/blob/master/GPU_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCKELhSS8hR4",
        "outputId": "c9762afe-24c7-43b6-c7ba-7f639477fa32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-wpzchx8t\n",
            "  Running command git clone -q https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-wpzchx8t\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4307 sha256=26934d1faa9fb4ec23d6d4209b20c4922fe8201e4f73b03c8ff17b5340076455\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g4yactkr/wheels/ca/33/8d/3c86eb85e97d2b6169d95c6e8f2c297fdec60db6e84cb56f5e\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czAyEkdn9NT3",
        "outputId": "0c478dea-fd8b-4cd3-9360-4c70cb35c5b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "    int\n",
        "    main()\n",
        "{\n",
        "    std::cout << \"Welcome To GeeksforGeeks\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naGMUDC29S7J",
        "outputId": "8cdd5baa-75cc-4ec3-bb47-b4c69b30d2e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome To GeeksforGeeks\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cstdio>\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "__global__ void cuda_hello(){\n",
        "  int a = 0;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  cuda_hello<<<1, 1>>>();\n",
        "  cout << \"aaaaa\";\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q66mkPWb9cEr",
        "outputId": "d4a8ca30-011d-4241-ac62-e28cd7cc8c9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aaaaa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cstdio>\n",
        "#include <iostream>\n",
        "\n",
        "\tusing namespace std;\n",
        "\n",
        "__global__ void maxi(int* a, int* b, int n)\n",
        "{\n",
        "\tint block = 256 * blockIdx.x;\n",
        "\tint max = 0;\n",
        "\n",
        "\tfor (int i = block; i < min(256 + block, n); i++) {\n",
        "\n",
        "\t\tif (max < a[i]) {\n",
        "\t\t\tmax = a[i];\n",
        "\t\t}\n",
        "\t}\n",
        "\tb[blockIdx.x] = max;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "\tint n;\n",
        "\tn = 3 >> 2;\n",
        "\tint a[n];\n",
        "\n",
        "\tfor (int i = 0; i < n; i++) {\n",
        "\t\ta[i] = rand() % n;\n",
        "\t\tcout << a[i] << \"\\t\";\n",
        "\t}\n",
        "\n",
        "\tcudaEvent_t start, end;\n",
        "\tint *ad, *bd;\n",
        "\tint size = n * sizeof(int);\n",
        "\tcudaMalloc(&ad, size);\n",
        "\tcudaMemcpy(ad, a, size, cudaMemcpyHostToDevice);\n",
        "\tint grids = ceil(n * 1.0f / 256.0f);\n",
        "\tcudaMalloc(&bd, grids * sizeof(int));\n",
        "\n",
        "\tdim3 grid(grids, 1);\n",
        "\tdim3 block(1, 1);\n",
        "\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEventCreate(&end);\n",
        "\tcudaEventRecord(start);\n",
        "\n",
        "\twhile (n > 1) {\n",
        "\t\tmaxi<<<grids, block>>>(ad, bd, n);\n",
        "\t\tn = ceil(n * 1.0f / 256.0f);\n",
        "\t\tcudaMemcpy(ad, bd, n * sizeof(int), cudaMemcpyDeviceToDevice);\n",
        "\t}\n",
        "\n",
        "\tcudaEventRecord(end);\n",
        "\tcudaEventSynchronize(end);\n",
        "\n",
        "\tfloat time = 0;\n",
        "\tcudaEventElapsedTime(&time, start, end);\n",
        "\n",
        "\tint ans[2];\n",
        "\tcudaMemcpy(ans, ad, 4, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\tcout << \"The maximum element is : \" << ans[0] << endl;\n",
        "\n",
        "\tcout << \"The time required : \";\n",
        "\tcout << time << endl;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El7fS7CU9p16",
        "outputId": "11e24ade-ef32-43ec-d090-b0f7f76c1a63"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum element is : 1445357584\n",
            "The time required : 0.002976\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hgpu_test1.cu\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "\n",
        "__global__ void add(int n, float *a, float *b){\n",
        "    for(int i = 0; i < n; i++){\n",
        "        b[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void){\n",
        "    \n",
        "    int N = 1 << 20;\n",
        "    float *x, *y;\n",
        "\n",
        "    // Allocate Unified Memory - Accessible from CPU and GPU.\n",
        "    cudaMallocManaged(&x, N*sizeof(float));\n",
        "    cudaMallocManaged(&y, N*sizeof(float));\n",
        "\n",
        "    // Initiallize x and y arrays on the Host\n",
        "    for(int i = 0; i < N; i++){\n",
        "        x[i] = 1.0f;\n",
        "        y[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    // Run kernel on 1M elements on GPU\n",
        "    add<<<1, 1>>>(N, x, y);\n",
        "\n",
        "    // Wait for GPU to finish before accessing on host\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    for(int i = 0; i < 5; i++){\n",
        "        cout << x[i] << \", \" << y[i] << endl;\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(x);\n",
        "    cudaFree(y);\n",
        "\n",
        "    return 0;\n",
        "\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F1HCXusSxI-",
        "outputId": "aba54638-94b5-4900-c4c0-79cf9fc6ee3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hgpu_test1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn54_vIeXdhY",
        "outputId": "8ec7d96a-6cca-451d-cc4b-a333bc8e9a45"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hgpu_test1.cpp\thgpu_test1.cu  sample_data  src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us6_s8WmgV4n",
        "outputId": "bd8e8cea-31b6-49ae-e8ce-afe31e2bd18a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc hgpu_test1.cu -o out1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kip3VgFFiGVf",
        "outputId": "bc95594c-d5ed-4414-91fc-f4d483f5e3e5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "./out1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwhumlJgiRkk",
        "outputId": "9901f50c-8012-473b-b89f-68a483af78d0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1, 3\n",
            "1, 3\n",
            "1, 3\n",
            "1, 3\n",
            "1, 3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvprof ./out1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyAmwKdviVfv",
        "outputId": "da2d82f0-308f-47ac-827c-3d8fca76cc5a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==960== NVPROF is profiling process 960, command: ./out1\n",
            "1, 3\n",
            "1, 3\n",
            "1, 3\n",
            "1, 3\n",
            "1, 3\n",
            "==960== Profiling application: ./out1\n",
            "==960== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  108.91ms         1  108.91ms  108.91ms  108.91ms  add(int, float*, float*)\n",
            "      API calls:   67.99%  234.06ms         2  117.03ms  55.940us  234.00ms  cudaMallocManaged\n",
            "                   31.64%  108.93ms         1  108.93ms  108.93ms  108.93ms  cudaDeviceSynchronize\n",
            "                    0.18%  632.64us         2  316.32us  251.20us  381.44us  cudaFree\n",
            "                    0.12%  408.14us         1  408.14us  408.14us  408.14us  cuDeviceTotalMem\n",
            "                    0.04%  154.66us       101  1.5310us     142ns  64.631us  cuDeviceGetAttribute\n",
            "                    0.02%  53.315us         1  53.315us  53.315us  53.315us  cudaLaunchKernel\n",
            "                    0.01%  28.168us         1  28.168us  28.168us  28.168us  cuDeviceGetName\n",
            "                    0.00%  5.8680us         1  5.8680us  5.8680us  5.8680us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.5950us         3     531ns     179ns  1.0900us  cuDeviceGetCount\n",
            "                    0.00%  1.3840us         2     692ns     464ns     920ns  cuDeviceGet\n",
            "                    0.00%     261ns         1     261ns     261ns     261ns  cuDeviceGetUuid\n",
            "\n",
            "==960== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "      48  170.67KB  4.0000KB  0.9961MB  8.000000MB  808.7500us  Host To Device\n",
            "       4  32.000KB  4.0000KB  60.000KB  128.0000KB  16.95900us  Device To Host\n",
            "      12         -         -         -           -  2.612910ms  Gpu page fault groups\n",
            "Total CPU Page faults: 26\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hgpu_test1.cu\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "\n",
        "__global__ void add(int n, float *a, float *b){\n",
        "    int index = threadIdx.x;\n",
        "    int stride = blockIdx.x;\n",
        "    for(int i = index; i < n; i += stride){\n",
        "      b[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void){\n",
        "    \n",
        "    int N = 1 << 20;\n",
        "    float *x, *y;\n",
        "\n",
        "    // Allocate Unified Memory - Accessible from CPU and GPU.\n",
        "    cudaMallocManaged(&x, N*sizeof(float));\n",
        "    cudaMallocManaged(&y, N*sizeof(float));\n",
        "\n",
        "    // Initiallize x and y arrays on the Host\n",
        "    for(int i = 0; i < N; i++){\n",
        "        x[i] = 1.0f;\n",
        "        y[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    // Run kernel on 1M elements on GPU\n",
        "    add<<<1, 256>>>(N, x, y);\n",
        "\n",
        "    // Wait for GPU to finish before accessing on host\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    for(int i = 0; i < 5; i++){\n",
        "        cout << x[i] << \", \" << y[i] << endl;\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(x);\n",
        "    cudaFree(y);\n",
        "\n",
        "    return 0;\n",
        "\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcS-WBMhif5V",
        "outputId": "92597e35-b19f-4dea-9b9f-73d461ed1568"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hgpu_test1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PewpaPWqxa9u",
        "outputId": "5d8f2a43-44e8-401d-86d2-b83cac1b9217"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hgpu_test1.cu  outx2  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc hgpu_test1.cu -o outx2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoNk98nvxdlO",
        "outputId": "da821622-2fa0-4f83-875b-02946501027d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "./outx2"
      ],
      "metadata": {
        "id": "S5ROv_1axrl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z8kbeevyxusU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}